{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Data Preparation Pipeline\n",
    "\n",
    "## Pipeline Overview\n",
    "\n",
    "**Stage 1: Environment Setup**\n",
    "- Initialize reproducible environment with fixed random seeds\n",
    "- Load and validate all configuration files\n",
    "- Audit raw data file inventory\n",
    "\n",
    "**Stage 3: Feature Engineering**\n",
    "- Select neuroimaging features by family (DTI, cortical area, thickness, etc.)\n",
    "- Create derived labels (anxiety groups from t-scores)\n",
    "- Apply transformations (e.g., sex coding)\n",
    "\n",
    "**Stage 4: Quality Control**\n",
    "- Apply surface holes QC policy to remove poor-quality scans\n",
    "- Generate QC visualizations and reports\n",
    "- Save pre-QC dataset for visualization and post-QC for downstream analysis\n",
    "\n",
    "**Stage 5: Data Splitting**\n",
    "- Create stratified train/validation/test splits\n",
    "- Ensure reproducible splits with fixed random seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from core.config import initialize_notebook\n",
    "#from core.preprocessing.pipeline import preprocess_abcd_data\n",
    "\n",
    "# Pass in name of notebook, default is \"anxiety\"\n",
    "# regenerate_run_id = True will create a new run id\n",
    "env = initialize_notebook()\n",
    "configs = env.configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train, val, test = preprocess_abcd_data(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.preprocessing.ingest import load_and_merge\n",
    "\n",
    "df = load_and_merge(env)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.preprocessing.splits import timepoint_split\n",
    "\n",
    "baseline, longitudinal = timepoint_split(env, df)\n",
    "display(baseline.head())\n",
    "display(longitudinal.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.preprocessing.transforms import recode, binning\n",
    "\n",
    "recoded = recode(env, baseline)\n",
    "binned = binning(env, recoded)\n",
    "display(recoded.head())\n",
    "display(binned.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.preprocessing.qc import quality_control\n",
    "\n",
    "qc_df, qc_mask = quality_control(env, binned)\n",
    "display(qc_df.head())\n",
    "display(qc_mask.head())\n",
    "\n",
    "total_pass = int(qc_mask[\"qc_pass\"].sum())\n",
    "total_fail = int((~qc_mask[\"qc_pass\"]).sum())\n",
    "\n",
    "print(f\"QC pass: {total_pass}\")\n",
    "print(f\"QC fail: {total_fail}\")\n",
    "if total_fail:\n",
    "    print(\n",
    "        \"Fail reasons:\\n\"\n",
    "        + qc_mask.loc[~qc_mask[\"qc_pass\"], \"qc_reason\"].value_counts().to_string()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.preprocessing.missing import (\n",
    "    summarize_missing,\n",
    "    handle_missing,\n",
    ")\n",
    "\n",
    "def imaging_columns(env, df):\n",
    "    \"\"\"Get imaging columns based on config prefixes.\"\"\"\n",
    "    imaging_cfg = env.configs.data[\"columns\"][\"imaging\"]\n",
    "    cols = []\n",
    "    for cfg in imaging_cfg.values():\n",
    "        prefixes = cfg.get(\"prefixes\", [])\n",
    "        cols.extend(\n",
    "            col for col in df.columns\n",
    "            if any(col.startswith(prefix) for prefix in prefixes)\n",
    "        )\n",
    "    return sorted(set(cols))\n",
    "\n",
    "def show_missing_summary(env, df, label):\n",
    "    \"\"\"Show missing data summary for metadata and imaging columns.\"\"\"\n",
    "    meta_cols = env.configs.data[\"columns\"][\"metadata\"]\n",
    "    imaging_cols = imaging_columns(env, df)\n",
    "    \n",
    "    meta_missing = summarize_missing(env, df[meta_cols])\n",
    "    imaging_missing = summarize_missing(env, df[imaging_cols])\n",
    "    \n",
    "    print(f\"=== {label} ===\")\n",
    "    display(meta_missing.head(10))\n",
    "    display(imaging_missing.head(10))\n",
    "\n",
    "# Show before cleanup\n",
    "show_missing_summary(env, qc_df, \"Before Cleanup\")\n",
    "\n",
    "# Apply missing data handling\n",
    "clean_df = handle_missing(env, qc_df, drop_rows=True)\n",
    "\n",
    "# Show after cleanup  \n",
    "show_missing_summary(env, clean_df, \"After Cleanup\")\n",
    "\n",
    "# Print summary statistics\n",
    "rows_removed = len(qc_df) - len(clean_df)\n",
    "columns_removed = len(qc_df.columns) - len(clean_df.columns)\n",
    "\n",
    "print(f\"=== Summary ===\")\n",
    "print(f\"Total rows removed: {rows_removed:,}\")\n",
    "print(f\"Total columns removed: {columns_removed:,}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (abcd)",
   "language": "python",
   "name": "abcd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
