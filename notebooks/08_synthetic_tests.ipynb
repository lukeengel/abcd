{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Pipeline Validation with Synthetic Data\n",
    "\n",
    "**Purpose:** Validate that our ML pipelines work correctly by testing on synthetic data with known structure.\n",
    "\n",
    "This notebook uses the **actual pipeline functions** (not raw sklearn) to verify:\n",
    "1. The pipeline code itself is bug-free\n",
    "2. Any poor performance on real data is due to data/signal, not code bugs\n",
    "\n",
    "**Realistic conditions tested:**\n",
    "- **Imbalanced data** (~20:1 ratio like real ABCD data)\n",
    "- **Site batch effects** (removed by ComBat harmonization)\n",
    "- **Downsampling** during training (100 iterations)\n",
    "- **Testing on full imbalanced data**\n",
    "\n",
    "**Tests:**\n",
    "- Test 1: Strong signal with realistic imbalance (should achieve >80% balanced accuracy)\n",
    "- Test 2: Moderate signal with realistic imbalance (should achieve >65% balanced accuracy)\n",
    "- Test 3: Weak signal with realistic imbalance (should beat chance >55%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import roc_curve, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from core.config import initialize_notebook\n",
    "\n",
    "# Initialize to get configs\n",
    "env = initialize_notebook(regenerate_run_id=False)\n",
    "\n",
    "SEED = env.configs.run['seed']\n",
    "np.random.seed(SEED)\n",
    "\n",
    "print(f\"Pipeline Validation with Synthetic Data\")\n",
    "print(f\"Random Seed: {SEED}\")\n",
    "print(f\"Research Question: {env.configs.run['run_name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "\n",
    "Create synthetic DataFrames that match the expected pipeline format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_synthetic_dataframe(\n",
    "    n_control: int,\n",
    "    n_clinical: int,\n",
    "    n_features: int = 100,\n",
    "    separation: float = 2.0,\n",
    "    noise_scale: float = 1.0,\n",
    "    seed: int = 42,\n",
    "    n_informative: int = 20,\n",
    "    site_effect_scale: float = 1.5,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create synthetic DataFrame matching pipeline expected format.\n",
    "    \n",
    "    Includes realistic site effects that ComBat should harmonize away,\n",
    "    while preserving the clinical vs control signal.\n",
    "    \n",
    "    Args:\n",
    "        n_control: Number of control samples\n",
    "        n_clinical: Number of clinical samples\n",
    "        n_features: Total number of imaging features\n",
    "        separation: Mean shift between classes (higher = easier to classify)\n",
    "        noise_scale: Standard deviation of noise\n",
    "        seed: Random seed\n",
    "        n_informative: Number of features with actual signal\n",
    "        site_effect_scale: Magnitude of site batch effects (ComBat should remove these)\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with imaging features, covariates, and group labels\n",
    "    \"\"\"\n",
    "    rng = np.random.RandomState(seed)\n",
    "    n_total = n_control + n_clinical\n",
    "    \n",
    "    # Define 3 sites with different batch effects\n",
    "    sites = ['Siemens', 'GE', 'Philips']\n",
    "    n_sites = len(sites)\n",
    "    \n",
    "    # Site-specific effects (mean shifts and scale differences)\n",
    "    # These should be REMOVED by ComBat harmonization\n",
    "    site_means = {\n",
    "        'Siemens': rng.randn(n_features) * site_effect_scale,\n",
    "        'GE': rng.randn(n_features) * site_effect_scale,\n",
    "        'Philips': rng.randn(n_features) * site_effect_scale,\n",
    "    }\n",
    "    site_scales = {\n",
    "        'Siemens': 1.0 + rng.uniform(-0.3, 0.3, n_features),\n",
    "        'GE': 1.0 + rng.uniform(-0.3, 0.3, n_features),\n",
    "        'Philips': 1.0 + rng.uniform(-0.3, 0.3, n_features),\n",
    "    }\n",
    "    \n",
    "    # Assign subjects to sites (roughly equal distribution)\n",
    "    site_assignments = rng.choice(sites, size=n_total)\n",
    "    \n",
    "    # Create base feature matrix with class signal\n",
    "    # Control: centered at 0\n",
    "    X_control = rng.randn(n_control, n_features) * noise_scale\n",
    "    \n",
    "    # Clinical: first n_informative features shifted by `separation`\n",
    "    X_clinical = rng.randn(n_clinical, n_features) * noise_scale\n",
    "    X_clinical[:, :n_informative] += separation\n",
    "    \n",
    "    X = np.vstack([X_control, X_clinical])\n",
    "    groups = ['Control'] * n_control + ['Clinical'] * n_clinical\n",
    "    \n",
    "    # Apply site-specific batch effects\n",
    "    # (ComBat should remove these while preserving class differences)\n",
    "    for i in range(n_total):\n",
    "        site = site_assignments[i]\n",
    "        X[i, :] = X[i, :] * site_scales[site] + site_means[site]\n",
    "    \n",
    "    # Create DataFrame with imaging column names (using dmri prefix)\n",
    "    imaging_cols = [f'dmri_dtimd_fibat_allfibers_{i}' for i in range(n_features)]\n",
    "    df = pd.DataFrame(X, columns=imaging_cols)\n",
    "    \n",
    "    # Add required metadata columns\n",
    "    df['src_subject_id'] = [f'NDAR_INV{i:08d}' for i in range(n_total)]\n",
    "    df['eventname'] = 'baseline_year_1_arm_1'\n",
    "    \n",
    "    # Add site column (needed for ComBat harmonization)\n",
    "    df['mri_info_manufacturer'] = site_assignments\n",
    "    \n",
    "    # Add covariates (needed for ComBat)\n",
    "    # Age: slight site differences (realistic - different recruitment)\n",
    "    base_age = rng.uniform(108, 132, size=n_total)\n",
    "    for i, site in enumerate(site_assignments):\n",
    "        if site == 'Siemens':\n",
    "            base_age[i] += rng.uniform(-2, 2)\n",
    "        elif site == 'GE':\n",
    "            base_age[i] += rng.uniform(-1, 3)\n",
    "    df['demo_brthdat_v2'] = base_age\n",
    "    \n",
    "    # Sex: balanced across sites\n",
    "    df['demo_sex_v2'] = rng.choice([1, 2], size=n_total)\n",
    "    df['sex_mapped'] = df['demo_sex_v2'].map({1: 'male', 2: 'female'})\n",
    "    \n",
    "    # Add group labels\n",
    "    df['psych_group'] = groups\n",
    "    df['anx_group'] = groups  # Same for anxiety\n",
    "    \n",
    "    # Add t-score (for anxiety research question compatibility)\n",
    "    df['cbcl_scr_dsm5_anxdisord_t'] = np.where(\n",
    "        df['psych_group'] == 'Control',\n",
    "        rng.uniform(40, 54, size=n_total),\n",
    "        rng.uniform(70, 90, size=n_total)\n",
    "    )\n",
    "    \n",
    "    # Shuffle to mix classes and sites\n",
    "    df = df.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "    \n",
    "    # Print site distribution\n",
    "    print(f\"Site distribution:\")\n",
    "    for site in sites:\n",
    "        n_site = (df['mri_info_manufacturer'] == site).sum()\n",
    "        n_ctrl = ((df['mri_info_manufacturer'] == site) & (df['psych_group'] == 'Control')).sum()\n",
    "        n_clin = ((df['mri_info_manufacturer'] == site) & (df['psych_group'] == 'Clinical')).sum()\n",
    "        print(f\"  {site}: {n_site} total ({n_ctrl} control, {n_clin} clinical)\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def get_synthetic_task_config(name: str = 'synthetic_test') -> dict:\n",
    "    \"\"\"Create task config for synthetic classification.\"\"\"\n",
    "    return {\n",
    "        'name': name,\n",
    "        'positive_class': 'Clinical',\n",
    "        'negative_class': 'Control',\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"Helper functions defined.\")\n",
    "print(\"\\nSynthetic data includes:\")\n",
    "print(\"  - Site-specific batch effects (mean shifts + scale differences)\")\n",
    "print(\"  - Class signal in first N features (clinical shifted from control)\")\n",
    "print(\"  - ComBat should remove site effects while preserving class signal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Test 1: Strong Signal with Realistic Imbalance\n",
    "\n",
    "Create data with strong class separation but realistic imbalance (~20:1 ratio).\n",
    "The pipeline should achieve **>80% balanced accuracy** despite the imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create synthetic data with strong signal and realistic imbalance\n",
    "df_easy = create_synthetic_dataframe(\n",
    "    n_control=2000,        # ~20:1 imbalance like real ABCD data\n",
    "    n_clinical=100,\n",
    "    n_features=100,\n",
    "    separation=3.0,        # Strong separation\n",
    "    noise_scale=0.5,       # Low noise\n",
    "    n_informative=30,      # Many informative features\n",
    "    site_effect_scale=1.5, # Realistic site effects\n",
    "    seed=SEED,\n",
    ")\n",
    "\n",
    "print(f\"\\nTest 1: Strong Signal with Realistic Imbalance\")\n",
    "print(f\"Total samples: {len(df_easy)}\")\n",
    "print(f\"Imbalance ratio: 1:{2000/100:.0f}\")\n",
    "print(f\"Feature columns: {len([c for c in df_easy.columns if c.startswith('dmri')])}\")\n",
    "print(f\"\\nThis mirrors real ABCD data structure:\")\n",
    "print(f\"  - High imbalance (downsampling will balance training)\")\n",
    "print(f\"  - Site effects (ComBat will harmonize)\")\n",
    "print(f\"  - Strong signal (should be detectable after preprocessing)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run SVM pipeline on easy synthetic data\n",
    "from core.svm.pipeline import run_task_with_nested_cv\n",
    "\n",
    "task_config_easy = get_synthetic_task_config('test1_easy')\n",
    "\n",
    "print(\"Running SVM pipeline on linearly separable synthetic data...\")\n",
    "print(\"(This tests the full pipeline: ComBat → PCA → Downsampling → SVM)\")\n",
    "print()\n",
    "\n",
    "results_easy = run_task_with_nested_cv(\n",
    "    env, \n",
    "    df_easy, \n",
    "    task_config_easy, \n",
    "    use_wandb=False, \n",
    "    sweep_mode=True  # Suppress file saving\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Test 1 results\n",
    "test1_bal_acc = results_easy['svm']['overall']['balanced_accuracy']\n",
    "test1_roc_auc = results_easy['svm']['overall']['roc_auc']\n",
    "test1_passed = test1_bal_acc > 0.80  # Slightly lower threshold due to imbalance\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"TEST 1 RESULTS: Strong Signal + Realistic Imbalance\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nSVM Performance:\")\n",
    "print(f\"  Balanced Accuracy: {test1_bal_acc:.3f}\")\n",
    "print(f\"  ROC-AUC: {test1_roc_auc:.3f}\")\n",
    "print(f\"  Per-fold std: {results_easy['svm']['per_fold']['balanced_accuracy_std']:.3f}\")\n",
    "print(f\"\\nBaseline (Logistic Regression):\")\n",
    "print(f\"  Balanced Accuracy: {results_easy['baseline']['overall']['balanced_accuracy']:.3f}\")\n",
    "print(f\"\\nExpected: >0.80 balanced accuracy\")\n",
    "print(f\"Status: {'PASSED' if test1_passed else 'FAILED'}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Test 2: Moderate Signal with Realistic Imbalance\n",
    "\n",
    "Create data with moderate signal and realistic imbalance.\n",
    "The pipeline should achieve **>65% balanced accuracy**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create synthetic data with moderate signal and realistic imbalance\n",
    "df_medium = create_synthetic_dataframe(\n",
    "    n_control=2000,        # ~20:1 imbalance\n",
    "    n_clinical=100,\n",
    "    n_features=100,\n",
    "    separation=1.5,        # Moderate separation\n",
    "    noise_scale=1.0,       # Medium noise\n",
    "    n_informative=15,      # Fewer informative features\n",
    "    site_effect_scale=1.5,\n",
    "    seed=SEED + 1,\n",
    ")\n",
    "\n",
    "print(f\"\\nTest 2: Moderate Signal with Realistic Imbalance\")\n",
    "print(f\"Total samples: {len(df_medium)}\")\n",
    "print(f\"Imbalance ratio: 1:{2000/100:.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run SVM pipeline on medium synthetic data\n",
    "task_config_medium = get_synthetic_task_config('test2_medium')\n",
    "\n",
    "print(\"Running SVM pipeline on moderately separable synthetic data...\")\n",
    "print()\n",
    "\n",
    "results_medium = run_task_with_nested_cv(\n",
    "    env, \n",
    "    df_medium, \n",
    "    task_config_medium, \n",
    "    use_wandb=False, \n",
    "    sweep_mode=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Test 2 results\n",
    "test2_bal_acc = results_medium['svm']['overall']['balanced_accuracy']\n",
    "test2_roc_auc = results_medium['svm']['overall']['roc_auc']\n",
    "test2_passed = test2_bal_acc > 0.65\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"TEST 2 RESULTS: Moderate Signal + Realistic Imbalance\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nSVM Performance:\")\n",
    "print(f\"  Balanced Accuracy: {test2_bal_acc:.3f}\")\n",
    "print(f\"  ROC-AUC: {test2_roc_auc:.3f}\")\n",
    "print(f\"  Per-fold std: {results_medium['svm']['per_fold']['balanced_accuracy_std']:.3f}\")\n",
    "print(f\"\\nBaseline (Logistic Regression):\")\n",
    "print(f\"  Balanced Accuracy: {results_medium['baseline']['overall']['balanced_accuracy']:.3f}\")\n",
    "print(f\"\\nExpected: >0.65 balanced accuracy\")\n",
    "print(f\"Status: {'PASSED' if test2_passed else 'FAILED'}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Test 3: Weak Signal with Realistic Imbalance (Hardest)\n",
    "\n",
    "Create data with weak signal and realistic imbalance - similar to real ABCD data conditions.\n",
    "The pipeline should **beat chance significantly** (>55% balanced accuracy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create synthetic data with weak signal and realistic imbalance (hardest test)\n",
    "df_hard = create_synthetic_dataframe(\n",
    "    n_control=2000,        # ~20:1 imbalance\n",
    "    n_clinical=100,\n",
    "    n_features=100,\n",
    "    separation=0.8,        # Weak separation (similar to real data?)\n",
    "    noise_scale=1.2,       # Higher noise\n",
    "    n_informative=10,      # Few informative features\n",
    "    site_effect_scale=1.5,\n",
    "    seed=SEED + 2,\n",
    ")\n",
    "\n",
    "print(f\"\\nTest 3: Weak Signal with Realistic Imbalance (Hardest)\")\n",
    "print(f\"Total samples: {len(df_hard)}\")\n",
    "print(f\"Imbalance ratio: 1:{2000/100:.0f}\")\n",
    "print(f\"\\nThis is closest to real ABCD data conditions:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run SVM pipeline on hard synthetic data\n",
    "task_config_hard = get_synthetic_task_config('test3_hard')\n",
    "\n",
    "print(\"Running SVM pipeline on imbalanced synthetic data...\")\n",
    "print()\n",
    "\n",
    "results_hard = run_task_with_nested_cv(\n",
    "    env, \n",
    "    df_hard, \n",
    "    task_config_hard, \n",
    "    use_wandb=False, \n",
    "    sweep_mode=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Test 3 results\n",
    "test3_bal_acc = results_hard['svm']['overall']['balanced_accuracy']\n",
    "test3_roc_auc = results_hard['svm']['overall']['roc_auc']\n",
    "test3_passed = test3_bal_acc > 0.55  # Must beat chance significantly\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"TEST 3 RESULTS: Weak Signal + Realistic Imbalance\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nSVM Performance:\")\n",
    "print(f\"  Balanced Accuracy: {test3_bal_acc:.3f}\")\n",
    "print(f\"  ROC-AUC: {test3_roc_auc:.3f}\")\n",
    "print(f\"  Per-fold std: {results_hard['svm']['per_fold']['balanced_accuracy_std']:.3f}\")\n",
    "print(f\"\\nBaseline (Logistic Regression):\")\n",
    "print(f\"  Balanced Accuracy: {results_hard['baseline']['overall']['balanced_accuracy']:.3f}\")\n",
    "print(f\"\\nExpected: >0.55 balanced accuracy (significantly better than chance)\")\n",
    "print(f\"Status: {'PASSED' if test3_passed else 'FAILED'}\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nNote: If real ABCD data achieves similar or worse performance,\")\n",
    "print(f\"it suggests the biological signal is weak, not that the pipeline is broken.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## Test Random Forest Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Random Forest pipeline on easy synthetic data\n",
    "from core.randomforest.pipeline import run_task_with_nested_cv as run_rf_task\n",
    "\n",
    "task_config_rf = get_synthetic_task_config('test_rf_easy')\n",
    "\n",
    "print(\"Running Random Forest pipeline on linearly separable synthetic data...\")\n",
    "print()\n",
    "\n",
    "results_rf = run_rf_task(\n",
    "    env, \n",
    "    df_easy, \n",
    "    task_config_rf, \n",
    "    use_wandb=False, \n",
    "    sweep_mode=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate RF results\n",
    "rf_bal_acc = results_rf['rf']['overall']['balanced_accuracy']\n",
    "rf_roc_auc = results_rf['rf']['overall']['roc_auc']\n",
    "rf_passed = rf_bal_acc > 0.80  # Same threshold as SVM for strong signal\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"RANDOM FOREST TEST RESULTS: Strong Signal + Imbalance\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nRandom Forest Performance:\")\n",
    "print(f\"  Balanced Accuracy: {rf_bal_acc:.3f}\")\n",
    "print(f\"  ROC-AUC: {rf_roc_auc:.3f}\")\n",
    "print(f\"\\nExpected: >0.80 balanced accuracy\")\n",
    "print(f\"Status: {'PASSED' if rf_passed else 'FAILED'}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "## Test MLP Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run MLP pipeline on easy synthetic data\n",
    "from core.mlp.pipeline import run_task_with_nested_cv as run_mlp_task\n",
    "\n",
    "task_config_mlp = get_synthetic_task_config('test_mlp_easy')\n",
    "\n",
    "print(\"Running MLP pipeline on linearly separable synthetic data...\")\n",
    "print()\n",
    "\n",
    "results_mlp = run_mlp_task(\n",
    "    env, \n",
    "    df_easy, \n",
    "    task_config_mlp, \n",
    "    use_wandb=False, \n",
    "    sweep_mode=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate MLP results\n",
    "mlp_bal_acc = results_mlp['mlp']['overall']['balanced_accuracy']\n",
    "mlp_roc_auc = results_mlp['mlp']['overall']['roc_auc']\n",
    "mlp_passed = mlp_bal_acc > 0.75  # Slightly lower - MLP can struggle with small minority class\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"MLP TEST RESULTS: Strong Signal + Imbalance\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nMLP Performance:\")\n",
    "print(f\"  Balanced Accuracy: {mlp_bal_acc:.3f}\")\n",
    "print(f\"  ROC-AUC: {mlp_roc_auc:.3f}\")\n",
    "print(f\"\\nExpected: >0.75 balanced accuracy\")\n",
    "print(f\"Status: {'PASSED' if mlp_passed else 'FAILED'}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "## Validation Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive validation summary\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PIPELINE VALIDATION SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nAll tests use realistic conditions:\")\n",
    "print(\"  - 20:1 class imbalance (like real ABCD data)\")\n",
    "print(\"  - Site batch effects (harmonized by ComBat)\")\n",
    "print(\"  - Downsampling during training\")\n",
    "print(\"  - Testing on full imbalanced data\")\n",
    "\n",
    "all_tests = [\n",
    "    (\"SVM - Strong signal\", test1_bal_acc, 0.80, test1_passed),\n",
    "    (\"SVM - Moderate signal\", test2_bal_acc, 0.65, test2_passed),\n",
    "    (\"SVM - Weak signal\", test3_bal_acc, 0.55, test3_passed),\n",
    "    (\"Random Forest - Strong\", rf_bal_acc, 0.80, rf_passed),\n",
    "    (\"MLP - Strong\", mlp_bal_acc, 0.75, mlp_passed),\n",
    "]\n",
    "\n",
    "print(f\"\\n{'Test':<30} | {'Bal Acc':^10} | {'Threshold':^10} | {'Status':^10}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "all_passed = True\n",
    "for test_name, bal_acc, threshold, passed in all_tests:\n",
    "    status = \"PASSED\" if passed else \"FAILED\"\n",
    "    print(f\"{test_name:<30} | {bal_acc:^10.3f} | {threshold:^10.2f} | {status:^10}\")\n",
    "    if not passed:\n",
    "        all_passed = False\n",
    "\n",
    "print(\"=\"*80)\n",
    "if all_passed:\n",
    "    print(\"\\nALL PIPELINE VALIDATION TESTS PASSED!\")\n",
    "    print(\"\\nConclusion:\")\n",
    "    print(\"  - The pipeline (ComBat → PCA → Downsampling → ML) works correctly\")\n",
    "    print(\"  - It can detect signal when signal exists, even with 20:1 imbalance\")\n",
    "    print(\"  - Poor performance on real ABCD data = weak biological signal, not code bugs\")\n",
    "else:\n",
    "    print(\"\\nSOME TESTS FAILED - Review pipeline implementations\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive summary visualization\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "fig.suptitle('Pipeline Validation Results (20:1 Imbalance)', fontsize=14, fontweight='bold')\n",
    "\n",
    "# 1. SVM by signal strength\n",
    "ax = axes[0, 0]\n",
    "difficulties = ['Strong\\n(sep=3.0)', 'Moderate\\n(sep=1.5)', 'Weak\\n(sep=0.8)']\n",
    "svm_accs = [test1_bal_acc, test2_bal_acc, test3_bal_acc]\n",
    "thresholds = [0.80, 0.65, 0.55]\n",
    "colors = ['green' if a > t else 'red' for a, t in zip(svm_accs, thresholds)]\n",
    "\n",
    "bars = ax.bar(difficulties, svm_accs, color=colors, alpha=0.7)\n",
    "for i, t in enumerate(thresholds):\n",
    "    ax.axhline(t, xmin=i/3, xmax=(i+1)/3, color='black', linestyle='--', alpha=0.5)\n",
    "ax.set_ylabel('Balanced Accuracy')\n",
    "ax.set_title('SVM: Performance by Signal Strength\\n(all with 20:1 imbalance)')\n",
    "ax.set_ylim([0.4, 1])\n",
    "ax.axhline(0.5, color='red', linestyle=':', alpha=0.3, label='Chance')\n",
    "ax.legend()\n",
    "\n",
    "# 2. Model comparison on strong signal data\n",
    "ax = axes[0, 1]\n",
    "models = ['SVM', 'Random\\nForest', 'MLP']\n",
    "model_accs = [test1_bal_acc, rf_bal_acc, mlp_bal_acc]\n",
    "model_thresholds = [0.80, 0.80, 0.75]\n",
    "model_colors = ['green' if a > t else 'red' for a, t in zip(model_accs, model_thresholds)]\n",
    "\n",
    "ax.bar(models, model_accs, color=model_colors, alpha=0.7)\n",
    "ax.axhline(0.80, color='black', linestyle='--', alpha=0.5, label='Threshold')\n",
    "ax.set_ylabel('Balanced Accuracy')\n",
    "ax.set_title('Model Comparison: Strong Signal\\n(20:1 imbalance)')\n",
    "ax.set_ylim([0.4, 1])\n",
    "ax.legend()\n",
    "\n",
    "# 3. ROC-AUC comparison\n",
    "ax = axes[0, 2]\n",
    "models_full = ['SVM\\nStrong', 'SVM\\nMod', 'SVM\\nWeak', 'RF', 'MLP']\n",
    "aucs = [test1_roc_auc, test2_roc_auc, test3_roc_auc, rf_roc_auc, mlp_roc_auc]\n",
    "\n",
    "ax.bar(models_full, aucs, color='steelblue', alpha=0.7)\n",
    "ax.axhline(0.5, color='red', linestyle=':', alpha=0.5, label='Chance')\n",
    "ax.set_ylabel('ROC-AUC')\n",
    "ax.set_title('ROC-AUC Across Tests')\n",
    "ax.set_ylim([0.4, 1])\n",
    "ax.legend()\n",
    "\n",
    "# 4. Test results summary\n",
    "ax = axes[1, 0]\n",
    "test_names = ['SVM\\nStrong', 'SVM\\nMod', 'SVM\\nWeak', 'RF', 'MLP']\n",
    "test_results = [test1_passed, test2_passed, test3_passed, rf_passed, mlp_passed]\n",
    "result_colors = ['green' if r else 'red' for r in test_results]\n",
    "\n",
    "ax.bar(test_names, [1 if r else 0 for r in test_results], color=result_colors, alpha=0.7)\n",
    "ax.set_ylabel('Status')\n",
    "ax.set_title('Test Pass/Fail Summary')\n",
    "ax.set_ylim([0, 1.3])\n",
    "ax.set_yticks([0, 1])\n",
    "ax.set_yticklabels(['Failed', 'Passed'])\n",
    "\n",
    "for i, (name, status) in enumerate(zip(test_names, test_results)):\n",
    "    ax.text(i, 0.5, '\\u2713' if status else '\\u2717', ha='center', va='center',\n",
    "            fontsize=24, color='white', fontweight='bold')\n",
    "\n",
    "# 5. Per-fold variance\n",
    "ax = axes[1, 1]\n",
    "fold_stds = [\n",
    "    results_easy['svm']['per_fold']['balanced_accuracy_std'],\n",
    "    results_medium['svm']['per_fold']['balanced_accuracy_std'],\n",
    "    results_hard['svm']['per_fold']['balanced_accuracy_std'],\n",
    "]\n",
    "ax.bar(['Strong', 'Moderate', 'Weak'], fold_stds, color='purple', alpha=0.7)\n",
    "ax.set_ylabel('Std Dev (Balanced Accuracy)')\n",
    "ax.set_title('SVM Per-Fold Variance')\n",
    "ax.set_ylim([0, max(fold_stds) * 1.5 if max(fold_stds) > 0 else 0.1])\n",
    "\n",
    "# 6. Summary table\n",
    "ax = axes[1, 2]\n",
    "ax.axis('off')\n",
    "\n",
    "table_data = [\n",
    "    ['Test', 'Model', 'Bal Acc', 'ROC-AUC', 'Status'],\n",
    "    ['Strong', 'SVM', f'{test1_bal_acc:.3f}', f'{test1_roc_auc:.3f}', 'PASS' if test1_passed else 'FAIL'],\n",
    "    ['Moderate', 'SVM', f'{test2_bal_acc:.3f}', f'{test2_roc_auc:.3f}', 'PASS' if test2_passed else 'FAIL'],\n",
    "    ['Weak', 'SVM', f'{test3_bal_acc:.3f}', f'{test3_roc_auc:.3f}', 'PASS' if test3_passed else 'FAIL'],\n",
    "    ['Strong', 'RF', f'{rf_bal_acc:.3f}', f'{rf_roc_auc:.3f}', 'PASS' if rf_passed else 'FAIL'],\n",
    "    ['Strong', 'MLP', f'{mlp_bal_acc:.3f}', f'{mlp_roc_auc:.3f}', 'PASS' if mlp_passed else 'FAIL'],\n",
    "]\n",
    "\n",
    "table = ax.table(cellText=table_data, cellLoc='center', loc='center',\n",
    "                 colWidths=[0.18, 0.15, 0.18, 0.18, 0.15])\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(9)\n",
    "table.scale(1, 1.8)\n",
    "\n",
    "# Style header\n",
    "for i in range(len(table_data[0])):\n",
    "    table[(0, i)].set_facecolor('#4CAF50')\n",
    "    table[(0, i)].set_text_props(weight='bold', color='white')\n",
    "\n",
    "# Color status column\n",
    "for i in range(1, len(table_data)):\n",
    "    status_cell = table[(i, 4)]\n",
    "    if table_data[i][4] == 'PASS':\n",
    "        status_cell.set_facecolor('#c8e6c9')\n",
    "    else:\n",
    "        status_cell.set_facecolor('#ffcdd2')\n",
    "\n",
    "ax.set_title('Results Summary', fontweight='bold', pad=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nValidation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "## Interpretation\n",
    "\n",
    "**All tests use realistic ABCD-like conditions:**\n",
    "- 20:1 class imbalance (2000 controls vs 100 clinical)\n",
    "- Site batch effects that ComBat must harmonize\n",
    "- Downsampling during training (100 iterations)\n",
    "- Testing on full imbalanced test set\n",
    "\n",
    "**If all tests pass:**\n",
    "- The full pipeline (ComBat → PCA → Downsampling → ML) works correctly\n",
    "- It can detect signal even with severe class imbalance\n",
    "- Poor performance on real ABCD data indicates **weak biological signal**, not code bugs\n",
    "\n",
    "**If tests fail:**\n",
    "- There may be bugs in the pipeline\n",
    "- Check: ComBat harmonization, PCA, downsampling logic, threshold optimization\n",
    "\n",
    "**Comparing to real ABCD results:**\n",
    "- If real data performs similar to \"Weak signal\" test → biological signal is weak\n",
    "- If real data performs worse than \"Weak signal\" test → may indicate no real signal or confounds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
