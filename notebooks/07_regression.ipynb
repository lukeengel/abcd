{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CBCL Subscale Regression with Nested Cross-Validation\n",
    "\n",
    "**Goal**: Predict continuous CBCL subscale scores from brain imaging features.\n",
    "\n",
    "**Approach**:\n",
    "- 5-fold nested CV for each target subscale\n",
    "- Test multiple models: Ridge, Elastic Net, Random Forest\n",
    "- Compare against baseline (Ridge regression)\n",
    "- Proper data hygiene: PCA fitted only on training folds\n",
    "\n",
    "**CBCL Subscales**:\n",
    "1. **Anxious/Depressed** (13 items) - anxiety and depressive symptoms\n",
    "2. **Somatic** (11 items) - physiological symptoms\n",
    "3. **Internalizing** (33 items) - combined anxious/depressed, somatic, withdrawn\n",
    "4. **Anxiety Problems** (6 items) - DSM-5 oriented scale (GAD, SAD, phobia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.config import initialize_notebook\n",
    "\n",
    "env = initialize_notebook(regenerate_run_id=False)\n",
    "\n",
    "research_question = env.configs.run['run_name']\n",
    "seed = env.configs.run['seed']\n",
    "use_pca = env.configs.regression.get('use_pca', True)\n",
    "\n",
    "print(f\"Research Question: {research_question.upper()}\")\n",
    "print(f\"Seed: {seed}\")\n",
    "print(f\"Use PCA: {use_pca}\")\n",
    "print(f\"Outer CV Folds: {env.configs.regression['cv']['n_outer_splits']}\")\n",
    "\n",
    "# Show enabled models\n",
    "models_config = env.configs.regression['models']\n",
    "enabled_models = [name for name, cfg in models_config.items() if cfg.get('enabled', True)]\n",
    "print(f\"\\nEnabled Models: {enabled_models}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.regression.pipeline import load_full_dataset\n",
    "\n",
    "# Load ALL data for nested CV (no fixed holdout)\n",
    "full_df = load_full_dataset(env)\n",
    "\n",
    "print(f\"Total samples for nested CV: {len(full_df):,} subjects\")\n",
    "\n",
    "# Show target distributions\n",
    "targets = env.configs.regression['targets']\n",
    "print(f\"\\nTarget distributions:\")\n",
    "for target in targets:\n",
    "    col = target['column']\n",
    "    if col in full_df.columns:\n",
    "        values = full_df[col].dropna()\n",
    "        print(f\"  {target['name']:20s}: n={len(values):4d}, \"\n",
    "              f\"mean={values.mean():5.2f}, std={values.std():5.2f}, \"\n",
    "              f\"range=[{values.min():.0f}, {values.max():.0f}]\")\n",
    "    else:\n",
    "        print(f\"  {target['name']:20s}: MISSING COLUMN '{col}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram & Sample Weighting Analysis\n",
    "\n",
    "Analyze target distribution and determine optimal weighting strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HISTOGRAM & SAMPLE WEIGHTING ANALYSIS\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# SELECT TASK TO ANALYZE\n",
    "# 0 = anxious_depressed\n",
    "# 1 = somatic\n",
    "# 2 = internalizing\n",
    "# 3 = anxiety_problems\n",
    "\n",
    "task_idx = 3  # Change this number (0-3) to analyze different tasks\n",
    "\n",
    "# Get both raw and t-score targets for this task\n",
    "raw_target_config = targets[task_idx]  # Raw score\n",
    "t_target_config = targets[task_idx + 4]  # T-score (4 positions later)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(f\"TARGET DISTRIBUTION ANALYSIS: {raw_target_config['name'].replace('_raw', '')}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Get configured custom bins from config\n",
    "weighting_cfg = env.configs.regression.get('sample_weighting', {})\n",
    "custom_bins_cfg = weighting_cfg.get('custom_bins', {})\n",
    "\n",
    "# Visualization - 2x2 grid\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Process both raw and t-score\n",
    "for row, target_config in enumerate([raw_target_config, t_target_config]):\n",
    "    target_name = target_config['name']\n",
    "    target_col = target_config['column']\n",
    "    y = full_df[target_col].dropna().values\n",
    "    \n",
    "    score_type = \"Raw Score\" if \"_raw\" in target_name else \"T-Score\"\n",
    "    \n",
    "    print(f\"\\n{score_type}:\")\n",
    "    print(f\"  n = {len(y):,}\")\n",
    "    print(f\"  Mean = {y.mean():.2f}, SD = {y.std():.2f}\")\n",
    "    print(f\"  Range = [{y.min():.0f}, {y.max():.0f}]\")\n",
    "    \n",
    "    # Equal-width bins (10 bins)\n",
    "    n_bins_equal = 10\n",
    "    bins_equal = np.linspace(y.min(), y.max(), n_bins_equal + 1)\n",
    "    bin_indices_equal = np.digitize(y, bins_equal) - 1\n",
    "    bin_indices_equal = np.clip(bin_indices_equal, 0, n_bins_equal - 1)\n",
    "    bin_counts_equal = np.bincount(bin_indices_equal, minlength=n_bins_equal)\n",
    "    \n",
    "    # Custom bins (if configured)\n",
    "    if target_name in custom_bins_cfg:\n",
    "        bin_edges = custom_bins_cfg[target_name]\n",
    "        n_bins_custom = len(bin_edges) - 1\n",
    "        bin_indices_custom = np.digitize(y, bin_edges) - 1\n",
    "        bin_indices_custom = np.clip(bin_indices_custom, 0, n_bins_custom - 1)\n",
    "        bin_counts_custom = np.bincount(bin_indices_custom, minlength=n_bins_custom)\n",
    "    else:\n",
    "        bin_edges = None\n",
    "        bin_counts_custom = None\n",
    "    \n",
    "    # Determine shared y-axis limit for this row\n",
    "    if bin_edges is not None:\n",
    "        max_count = max(bin_counts_equal.max(), bin_counts_custom.max())\n",
    "    else:\n",
    "        max_count = bin_counts_equal.max()\n",
    "    y_limit = max_count * 1.1\n",
    "    \n",
    "    # Left column: Equal-width bins\n",
    "    ax = axes[row, 0]\n",
    "    bin_centers_equal = [(bins_equal[i] + bins_equal[i+1])/2 for i in range(n_bins_equal)]\n",
    "    min_count_equal = bin_counts_equal[bin_counts_equal > 0].min()\n",
    "    colors_equal = ['red' if count == min_count_equal else 'steelblue' for count in bin_counts_equal]\n",
    "    ax.bar(bin_centers_equal, bin_counts_equal, width=(bins_equal[1]-bins_equal[0]), \n",
    "           color=colors_equal, alpha=0.7, edgecolor='black')\n",
    "    ax.axhline(min_count_equal, color='red', linestyle='--', linewidth=2, label=f'Min={min_count_equal}')\n",
    "    ax.set_xlabel('Bin Center', fontweight='bold', fontsize=11)\n",
    "    ax.set_ylabel('Sample Count', fontweight='bold', fontsize=11)\n",
    "    ax.set_title(f'{score_type} - Equal-Width Bins (n={n_bins_equal})', fontweight='bold', fontsize=12)\n",
    "    ax.set_ylim([0, y_limit])\n",
    "    ax.legend(fontsize=9)\n",
    "    ax.grid(alpha=0.3)\n",
    "    \n",
    "    # Right column: Custom bins\n",
    "    ax = axes[row, 1]\n",
    "    if bin_edges is not None:\n",
    "        bin_widths_custom = [bin_edges[i+1] - bin_edges[i] for i in range(n_bins_custom)]\n",
    "        bin_centers_custom = [(bin_edges[i] + bin_edges[i+1])/2 for i in range(n_bins_custom)]\n",
    "        min_count_custom = bin_counts_custom[bin_counts_custom > 0].min()\n",
    "        colors_custom = ['red' if count == min_count_custom else 'orange' for count in bin_counts_custom]\n",
    "        \n",
    "        ax.bar(bin_centers_custom, bin_counts_custom, width=bin_widths_custom,\n",
    "               color=colors_custom, alpha=0.7, edgecolor='black')\n",
    "        ax.axhline(min_count_custom, color='red', linestyle='--', linewidth=2, label=f'Min={min_count_custom}')\n",
    "        ax.set_xlabel('Bin Center', fontweight='bold', fontsize=11)\n",
    "        ax.set_ylabel('Sample Count', fontweight='bold', fontsize=11)\n",
    "        ax.set_title(f'{score_type} - Custom Bins (n={n_bins_custom})', fontweight='bold', fontsize=12)\n",
    "        ax.set_ylim([0, y_limit])\n",
    "        ax.legend(fontsize=9)\n",
    "        ax.grid(alpha=0.3)\n",
    "    else:\n",
    "        ax.text(0.5, 0.5, 'No custom bins configured', \n",
    "                ha='center', va='center', fontsize=12, transform=ax.transAxes)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "fig.suptitle(f'{raw_target_config[\"name\"].replace(\"_raw\", \"\").replace(\"_\", \" \").title()} - Distribution Comparison', \n",
    "             fontweight='bold', fontsize=14, y=0.995)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print detailed tables\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"EQUAL-WIDTH BINS:\")\n",
    "print(f\"{'='*70}\")\n",
    "for target_config in [raw_target_config, t_target_config]:\n",
    "    target_col = target_config['column']\n",
    "    y = full_df[target_col].dropna().values\n",
    "    score_type = \"Raw\" if \"_raw\" in target_config['name'] else \"T-Score\"\n",
    "    \n",
    "    n_bins_equal = 10\n",
    "    bins_equal = np.linspace(y.min(), y.max(), n_bins_equal + 1)\n",
    "    bin_indices_equal = np.digitize(y, bins_equal) - 1\n",
    "    bin_indices_equal = np.clip(bin_indices_equal, 0, n_bins_equal - 1)\n",
    "    bin_counts_equal = np.bincount(bin_indices_equal, minlength=n_bins_equal)\n",
    "    \n",
    "    print(f\"\\n{score_type}:\")\n",
    "    print(f\"{'Bin':>5} {'Range':>15} {'Count':>8} {'%':>7}\")\n",
    "    print(\"-\"*40)\n",
    "    for i in range(n_bins_equal):\n",
    "        count = bin_counts_equal[i]\n",
    "        pct = 100 * count / len(y)\n",
    "        print(f\"{i:>5} {bins_equal[i]:6.1f}-{bins_equal[i+1]:6.1f} {count:8,} {pct:6.1f}%\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"CUSTOM BINS:\")\n",
    "print(f\"{'='*70}\")\n",
    "for target_config in [raw_target_config, t_target_config]:\n",
    "    target_name = target_config['name']\n",
    "    target_col = target_config['column']\n",
    "    y = full_df[target_col].dropna().values\n",
    "    score_type = \"Raw\" if \"_raw\" in target_name else \"T-Score\"\n",
    "    \n",
    "    if target_name in custom_bins_cfg:\n",
    "        bin_edges = custom_bins_cfg[target_name]\n",
    "        n_bins_custom = len(bin_edges) - 1\n",
    "        bin_indices_custom = np.digitize(y, bin_edges) - 1\n",
    "        bin_indices_custom = np.clip(bin_indices_custom, 0, n_bins_custom - 1)\n",
    "        bin_counts_custom = np.bincount(bin_indices_custom, minlength=n_bins_custom)\n",
    "        weights_per_bin = len(y) / (n_bins_custom * np.maximum(bin_counts_custom, 1))\n",
    "        \n",
    "        print(f\"\\n{score_type}:\")\n",
    "        print(f\"{'Bin':>5} {'Range':>15} {'Count':>8} {'%':>7} {'Inv Weight':>12}\")\n",
    "        print(\"-\"*55)\n",
    "        for i in range(n_bins_custom):\n",
    "            count = bin_counts_custom[i]\n",
    "            pct = 100 * count / len(y)\n",
    "            weight = weights_per_bin[i]\n",
    "            print(f\"{i:>5} {bin_edges[i]:6.1f}-{bin_edges[i+1]:6.1f} {count:8,} {pct:6.1f}% {weight:11.2f}x\")\n",
    "        \n",
    "        min_bin = bin_counts_custom.min()\n",
    "        max_bin = bin_counts_custom.max()\n",
    "        imbalance = max_bin / max(min_bin, 1)\n",
    "        print(f\"  Imbalance ratio: {imbalance:.1f}:1\")\n",
    "    else:\n",
    "        print(f\"\\n{score_type}: No custom bins configured\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Regression for Single Target\n",
    "\n",
    "Start with one target and one model to test the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.regression.pipeline import run_target_with_nested_cv\n",
    "\n",
    "# Select target to predict\n",
    "# RAW SCORES (discrete 0-26, zero-inflated):\n",
    "#   0 = anxious_depressed_raw\n",
    "#   1 = somatic_raw\n",
    "#   2 = internalizing_raw\n",
    "#   3 = anxiety_problems_raw\n",
    "#\n",
    "# T-SCORES (normalized, mean=50 SD=10, more continuous - RECOMMENDED):\n",
    "#   4 = anxious_depressed_t\n",
    "#   5 = somatic_t\n",
    "#   6 = internalizing_t\n",
    "#   7 = anxiety_problems_t\n",
    "\n",
    "target_idx = 7 # Change this number (0-7) to test different subscales\n",
    "target_config = targets[target_idx]\n",
    "\n",
    "# Select model\n",
    "model_name = 'linear'  # Options: 'ridge', 'random_forest', 'elastic_net', 'linear'\n",
    "\n",
    "\n",
    "print(f\"Running: {target_config['name']} with {model_name.upper()}\\n\")\n",
    "\n",
    "# Run the regression with nested CV\n",
    "results = run_target_with_nested_cv(env, full_df, target_config, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIAGNOSTIC: Check Sample Weights\n",
    "from core.regression.pipeline import apply_sample_weighting, filter_target_data\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"SAMPLE WEIGHTING DIAGNOSTIC\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Get target\n",
    "df_filtered, y = filter_target_data(full_df, target_config)\n",
    "target_name = target_config['name']\n",
    "\n",
    "# Create CV splitter\n",
    "y_binned = pd.qcut(y, q=5, labels=False, duplicates='drop')\n",
    "outer_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "\n",
    "# Get first fold\n",
    "train_idx, test_idx = list(outer_cv.split(df_filtered, y_binned))[0]\n",
    "y_train = y[train_idx]\n",
    "\n",
    "print(f\"\\nTarget: {target_name}\")\n",
    "print(f\"Total training samples: {len(y_train)}\")\n",
    "print(f\"Training target stats: mean={y_train.mean():.2f}, std={y_train.std():.2f}\")\n",
    "\n",
    "# Check if weighting is enabled\n",
    "weighting_cfg = env.configs.regression.get('sample_weighting', {})\n",
    "if weighting_cfg.get('enabled', False):\n",
    "    print(f\"\\nSample weighting: ENABLED\")\n",
    "    print(f\"Method: {weighting_cfg.get('method', 'inverse_freq')}\")\n",
    "    \n",
    "    # Apply weighting\n",
    "    try:\n",
    "        valid_mask, weights = apply_sample_weighting(y_train, target_name, env, method=\"inverse_freq\")\n",
    "        \n",
    "        print(f\"\\nFiltering results:\")\n",
    "        print(f\"  Valid samples (within bins): {valid_mask.sum()}\")\n",
    "        print(f\"  Excluded samples: {(~valid_mask).sum()}\")\n",
    "        \n",
    "        if (~valid_mask).sum() > 0:\n",
    "            excluded_values = y_train[~valid_mask]\n",
    "            print(f\"  Excluded values range: [{excluded_values.min():.1f}, {excluded_values.max():.1f}]\")\n",
    "        \n",
    "        print(f\"\\nWeight statistics:\")\n",
    "        print(f\"  Min weight: {weights.min():.3f}\")\n",
    "        print(f\"  Max weight: {weights.max():.3f}\")\n",
    "        print(f\"  Mean weight: {weights.mean():.3f}\")\n",
    "        print(f\"  Weight ratio (max/min): {weights.max()/weights.min():.1f}x\")\n",
    "        \n",
    "        # Get bins from config\n",
    "        custom_bins_cfg = weighting_cfg.get('custom_bins', {})\n",
    "        if target_name in custom_bins_cfg:\n",
    "            bin_edges = custom_bins_cfg[target_name]\n",
    "            y_valid = y_train[valid_mask]\n",
    "            \n",
    "            print(f\"\\nPer-bin breakdown:\")\n",
    "            print(f\"{'Bin':>5} {'Range':>15} {'Count':>8} {'%':>7} {'Weight':>10}\")\n",
    "            print(\"-\"*55)\n",
    "            \n",
    "            for i in range(len(bin_edges)-1):\n",
    "                bin_min = bin_edges[i]\n",
    "                bin_max = bin_edges[i+1]\n",
    "                mask = (y_valid >= bin_min) & (y_valid < bin_max)\n",
    "                if mask.sum() > 0:\n",
    "                    weight = weights[mask][0]\n",
    "                    pct = 100 * mask.sum() / len(y_valid)\n",
    "                    print(f\"{i:>5} {bin_min:6.1f}-{bin_max:6.1f} {mask.sum():8,} {pct:6.1f}% {weight:9.3f}\")\n",
    "            \n",
    "            # Check if high-score bins actually have high weights\n",
    "            high_bin_idx = len(bin_edges) - 2  # Last bin\n",
    "            high_bin_min = bin_edges[high_bin_idx]\n",
    "            high_mask = y_valid >= high_bin_min\n",
    "            if high_mask.sum() > 0:\n",
    "                high_weight = weights[high_mask][0]\n",
    "                print(f\"  High-score bin ({high_bin_min}+): n={high_mask.sum()}, weight={high_weight:.3f}\")\n",
    "                if high_weight < 1.0:\n",
    "                    print(f\"  PROBLEM: High scores have LOWER weight than average!\")\n",
    "                else:\n",
    "                    print(f\"  High scores have higher weight (good)\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nERROR applying weights: {e}\")\n",
    "else:\n",
    "    print(f\"\\nSample weighting: DISABLED\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall metrics (aggregated from all 5 folds)\n",
    "print(\"=\"*70)\n",
    "print(\"OVERALL RESULTS (All 5 folds aggregated)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "\n",
    "print(f\"\\n{model_name.upper()}:\")\n",
    "for metric, value in results[model_name]['overall'].items():\n",
    "    print(f\"  {metric:15s}: {value:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PER-FOLD STATISTICS (Mean ± Std)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\n{model_name.upper()} Per-Fold:\")\n",
    "for metric, value in results[model_name]['per_fold'].items():\n",
    "    print(f\"  {metric:20s}: {value:.4f}\")\n",
    "\n",
    "print(f\"\\nTotal samples tested: {results[model_name]['n_samples']}\")\n",
    "print(f\"Number of folds: {results[model_name]['n_folds']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Visualizations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from pathlib import Path\n",
    "\n",
    "run_cfg = env.configs.run\n",
    "target_name = target_config['name']\n",
    "plots_dir = (env.repo_root / \"outputs\" / run_cfg['run_name'] / run_cfg['run_id'] / \n",
    "             f\"seed_{seed}\" / \"regression\" / target_name / model_name / \"plots\")\n",
    "\n",
    "print(f\"Plots directory: {plots_dir}\\n\")\n",
    "\n",
    "# Display NEW enhanced prediction plot with confidence intervals\n",
    "print(\"=\"*70)\n",
    "print(\"BRAIN-BEHAVIOR SCATTERPLOT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "display(Image(str(plots_dir / f\"predictions_{model_name}_{target_name}.png\")))\n",
    "\n",
    "# Display NEW coefficient plot (for Ridge/ElasticNet only)\n",
    "if model_name in ['linear', 'ridge', 'elastic_net']:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"COEFFICIENT PLOT (Top 30 Features)\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"Red = Positive (predicts higher symptoms)\")\n",
    "    print(\"Blue = Negative (protective)\\n\")\n",
    "    display(Image(str(plots_dir / f\"coefficients_{model_name}_{target_name}.png\")))\n",
    "\n",
    "# Display NEW comprehensive summary figure\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPREHENSIVE SUMMARY (4-Panel Figure)\")\n",
    "print(\"=\"*70)\n",
    "print(\"(A) Brain-behavior prediction\")\n",
    "print(\"(B) Residual analysis\")\n",
    "print(\"(C) Top feature coefficients\" if model_name in ['ridge', 'elastic_net'] else \"(C) Distribution comparison\")\n",
    "print(\"(D) Score distributions\\n\")\n",
    "display(Image(str(plots_dir / f\"summary_{model_name}_{target_name}.png\")))\n",
    "\n",
    "# Display residuals\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RESIDUAL ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "display(Image(str(plots_dir / f\"residuals_{model_name}_{target_name}.png\")))\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"All plots saved to:\")\n",
    "print(f\"  {plots_dir}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run All Targets and Models (Optional)\n",
    "\n",
    "Once single target works, run the complete pipeline for all targets and models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HISTOGRAM & SAMPLE WEIGHTING ANALYSIS\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(f\"TARGET DISTRIBUTION ANALYSIS: {target_config['name']}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Get target values\n",
    "target_col = target_config['column']\n",
    "y = full_df[target_col].dropna().values\n",
    "\n",
    "print(f\"\\nBasic Statistics:\")\n",
    "print(f\"  n = {len(y):,}\")\n",
    "print(f\"  Mean = {y.mean():.2f}, SD = {y.std():.2f}\")\n",
    "print(f\"  Range = [{y.min():.0f}, {y.max():.0f}]\")\n",
    "print(f\"  Unique values: {len(np.unique(y))}\")\n",
    "\n",
    "# Create bins for weighting\n",
    "n_bins = 10  # Change this to adjust granularity\n",
    "bins = np.linspace(y.min(), y.max(), n_bins + 1)\n",
    "bin_indices = np.digitize(y, bins) - 1\n",
    "bin_indices = np.clip(bin_indices, 0, n_bins - 1)  # Handle edge case\n",
    "\n",
    "# Count samples per bin\n",
    "bin_counts = np.bincount(bin_indices, minlength=n_bins)\n",
    "bin_edges = [(bins[i], bins[i+1]) for i in range(n_bins)]\n",
    "\n",
    "print(f\"\\nDistribution across {n_bins} bins:\")\n",
    "print(f\"{'Bin':>5} {'Range':>15} {'Count':>8} {'%':>7} {'Inv Freq Weight':>17}\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "for i in range(n_bins):\n",
    "    count = bin_counts[i]\n",
    "    pct = 100 * count / len(y)\n",
    "    \n",
    "    # Inverse frequency weight\n",
    "    inv_freq_weight = len(y) / (n_bins * (count + 1)) if count > 0 else 0\n",
    "    \n",
    "    print(f\"{i:>5} {bins[i]:6.1f}-{bins[i+1]:6.1f} {count:8,} {pct:6.1f}% {inv_freq_weight:16.2f}\")\n",
    "\n",
    "# Find smallest bin\n",
    "min_bin_count = bin_counts[bin_counts > 0].min()\n",
    "print(f\"\\nSmallest bin has: {min_bin_count:,} samples\")\n",
    "\n",
    "# Strategy comparison\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"WEIGHTING STRATEGIES:\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n1. INVERSE FREQUENCY (recommended):\")\n",
    "print(\"   Weight = n_total / (n_bins × bin_count)\")\n",
    "print(\"   → Rare bins get higher weight\")\n",
    "print(\"   → All bins contribute equally to loss\")\n",
    "print(f\"   → Weight range: {len(y) / (n_bins * bin_counts.max()):.2f} to {len(y) / (n_bins * min_bin_count):.2f}\")\n",
    "\n",
    "print(\"\\n2. DOWNSAMPLE TO SMALLEST BIN:\")\n",
    "print(\"   Use only {min_bin_count} samples per bin\")\n",
    "print(f\"   → Total samples: {n_bins * min_bin_count:,} (from {len(y):,})\")\n",
    "print(f\"   → Discards: {len(y) - n_bins * min_bin_count:,} samples ({100*(len(y) - n_bins * min_bin_count)/len(y):.1f}%)\")\n",
    "print(\"   → Equal representation but loses data\")\n",
    "\n",
    "print(\"\\n3. UPSAMPLE RARE BINS (duplicate):\")\n",
    "print(\"   Duplicate samples in rare bins to match largest bin\")\n",
    "max_bin_count = bin_counts.max()\n",
    "total_upsampled = sum(max_bin_count for _ in range(n_bins))\n",
    "print(f\"   → Total samples: {total_upsampled:,} (from {len(y):,})\")\n",
    "print(f\"   → Creates: {total_upsampled - len(y):,} duplicates\")\n",
    "print(\"   → Balanced but overfits to duplicates\")\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# 1. Histogram of target values\n",
    "ax = axes[0, 0]\n",
    "ax.hist(y, bins=30, color='steelblue', alpha=0.7, edgecolor='black')\n",
    "ax.axvline(y.mean(), color='red', linestyle='--', linewidth=2, label=f'Mean={y.mean():.1f}')\n",
    "ax.axvline(y.median(), color='orange', linestyle='--', linewidth=2, label=f'Median={y.median():.1f}')\n",
    "ax.set_xlabel('Target Value', fontweight='bold', fontsize=12)\n",
    "ax.set_ylabel('Frequency', fontweight='bold', fontsize=12)\n",
    "ax.set_title('(A) Target Distribution', fontweight='bold', fontsize=13)\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "# 2. Bin counts\n",
    "ax = axes[0, 1]\n",
    "bin_centers = [(bins[i] + bins[i+1])/2 for i in range(n_bins)]\n",
    "colors = ['red' if count == min_bin_count else 'steelblue' for count in bin_counts]\n",
    "ax.bar(bin_centers, bin_counts, width=(bins[1]-bins[0])*0.8, color=colors, alpha=0.7, edgecolor='black')\n",
    "ax.axhline(min_bin_count, color='red', linestyle='--', linewidth=2, label=f'Min bin={min_bin_count}')\n",
    "ax.set_xlabel('Bin Center', fontweight='bold', fontsize=12)\n",
    "ax.set_ylabel('Sample Count', fontweight='bold', fontsize=12)\n",
    "ax.set_title(f'(B) Samples per Bin (n={n_bins})', fontweight='bold', fontsize=13)\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "# 3. Inverse frequency weights\n",
    "ax = axes[1, 0]\n",
    "inv_weights = [len(y) / (n_bins * (count + 1)) for count in bin_counts]\n",
    "ax.bar(bin_centers, inv_weights, width=(bins[1]-bins[0])*0.8, color='orange', alpha=0.7, edgecolor='black')\n",
    "ax.axhline(1.0, color='black', linestyle='--', linewidth=1, alpha=0.5, label='Weight=1.0')\n",
    "ax.set_xlabel('Bin Center', fontweight='bold', fontsize=12)\n",
    "ax.set_ylabel('Inverse Frequency Weight', fontweight='bold', fontsize=12)\n",
    "ax.set_title('(C) Inverse Frequency Weights', fontweight='bold', fontsize=13)\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "# 4. Cumulative distribution\n",
    "ax = axes[1, 1]\n",
    "sorted_y = np.sort(y)\n",
    "cumulative = np.arange(1, len(y)+1) / len(y) * 100\n",
    "ax.plot(sorted_y, cumulative, linewidth=2, color='steelblue')\n",
    "ax.axhline(50, color='red', linestyle='--', alpha=0.5, label='50th percentile')\n",
    "ax.axhline(75, color='orange', linestyle='--', alpha=0.5, label='75th percentile')\n",
    "ax.axhline(90, color='green', linestyle='--', alpha=0.5, label='90th percentile')\n",
    "ax.set_xlabel('Target Value', fontweight='bold', fontsize=12)\n",
    "ax.set_ylabel('Cumulative %', fontweight='bold', fontsize=12)\n",
    "ax.set_title('(D) Cumulative Distribution', fontweight='bold', fontsize=13)\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Recommendation\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RECOMMENDATION:\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "imbalance_ratio = bin_counts.max() / min_bin_count\n",
    "print(f\"\\nImbalance ratio: {imbalance_ratio:.1f}:1 (max bin / min bin)\")\n",
    "\n",
    "if imbalance_ratio > 20:\n",
    "    print(\"\\n✓ USE INVERSE FREQUENCY WEIGHTING\")\n",
    "    print(\"  → High imbalance (>20:1) makes downsampling wasteful\")\n",
    "    print(\"  → Keeps all data while balancing contribution\")\n",
    "    print(\"  → Equivalent to upsampling but computationally efficient\")\n",
    "elif imbalance_ratio > 5:\n",
    "    print(\"\\n✓ EITHER INVERSE FREQUENCY OR DOWNSAMPLE\")\n",
    "    print(\"  → Moderate imbalance (5-20:1)\")\n",
    "    print(\"  → Inverse freq: keeps all data\")\n",
    "    print(\"  → Downsample: simpler, forces balance\")\n",
    "else:\n",
    "    print(\"\\n⚠️  MINOR IMBALANCE\")\n",
    "    print(\"  → May not need weighting\")\n",
    "    print(\"  → Try standard regression first\")\n",
    "\n",
    "print(f\"\\nTo use inverse frequency weighting, add to regression.yaml:\")\n",
    "print(\"\"\"\n",
    "sample_weighting:\n",
    "  enabled: true\n",
    "  method: inverse_freq\n",
    "  n_bins: 10\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.regression.pipeline import run_regression_pipeline\n",
    "\n",
    "# Run complete pipeline for all targets and enabled models\n",
    "all_results = run_regression_pipeline(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Models Across All Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create comparison table\n",
    "comparison_data = []\n",
    "\n",
    "for target_name, target_results in all_results.items():\n",
    "    for model_name, model_results in target_results.items():\n",
    "        if model_name != 'baseline':\n",
    "            comparison_data.append({\n",
    "                'Target': target_name,\n",
    "                'Model': model_name,\n",
    "                'R²': model_results[model_name]['overall']['r2'],\n",
    "                'MAE': model_results[model_name]['overall']['mae'],\n",
    "                'RMSE': model_results[model_name]['overall']['rmse'],\n",
    "                'Pearson r': model_results[model_name]['overall']['pearson_r'],\n",
    "            })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL COMPARISON ACROSS ALL TARGETS\")\n",
    "print(\"=\"*80)\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Best model for each target\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BEST MODEL FOR EACH TARGET (by R²)\")\n",
    "print(\"=\"*80)\n",
    "for target_name in comparison_df['Target'].unique():\n",
    "    target_data = comparison_df[comparison_df['Target'] == target_name]\n",
    "    best_idx = target_data['R²'].idxmax()\n",
    "    best_row = target_data.loc[best_idx]\n",
    "    print(f\"  {target_name:20s}: {best_row['Model']:15s} (R²={best_row['R²']:.3f}, MAE={best_row['MAE']:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance (Linear Models Only)\n",
    "\n",
    "For Ridge and Elastic Net, examine coefficients to see which brain regions predict CBCL scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load results for a specific target and model\n",
    "target_name = targets[0]['name']  # Change to analyze different target\n",
    "model_name = 'ridge'  # Must be 'ridge' or 'elastic_net'\n",
    "\n",
    "results_path = (env.repo_root / \"outputs\" / run_cfg['run_name'] / run_cfg['run_id'] /\n",
    "                f\"seed_{seed}\" / \"regression\" / target_name / model_name / \"results.pkl\")\n",
    "\n",
    "with open(results_path, \"rb\") as f:\n",
    "    saved_results = pickle.load(f)\n",
    "\n",
    "# Get coefficients from last fold as representative\n",
    "last_fold = saved_results[f\"{model_name}_folds\"][-1]\n",
    "model = last_fold['model']\n",
    "coefficients = model.coef_\n",
    "\n",
    "# Create feature names\n",
    "if use_pca:\n",
    "    n_components = len(coefficients)\n",
    "    feature_names = [f\"PC{i+1}\" for i in range(n_components)]\n",
    "else:\n",
    "    # TODO: Get actual feature names from preprocessing\n",
    "    feature_names = [f\"Feature{i+1}\" for i in range(len(coefficients))]\n",
    "\n",
    "# Create importance dataframe\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'coefficient': coefficients,\n",
    "    'abs_coefficient': np.abs(coefficients)\n",
    "})\n",
    "\n",
    "importance_df = importance_df.sort_values('abs_coefficient', ascending=False)\n",
    "\n",
    "print(f\"\\nTop 20 Features for {target_name} ({model_name.upper()}):\")\n",
    "print(\"=\"*60)\n",
    "print(importance_df.head(20).to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (abcd)",
   "language": "python",
   "name": "abcd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
